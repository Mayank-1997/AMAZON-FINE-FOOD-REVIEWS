{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yE_CEe9g5GJ5"
   },
   "source": [
    "# OBJECTIVE :#\n",
    "\n",
    "1.   <b>APPLYING LOGISTIC REGRESSION WITH BOW VECTORIZATION\n",
    " * PERFORMING PERTUBATION TEST TO CHECK WHETHER OUR DATA  FEATURES ARE COLLINER OR NOT AND PLOTTING THE RESULT\n",
    " *   FINDING THE BEST HYPERPARAMETER USING GRIDSEARCHCV WITH TRAIN DATA AND CROSS-VALIDATION DATA BY PLOTTING THE RESLUTS OF VAROIUS TRAIN DATA AND CROSS VALIDATION DATA\n",
    " * USING THE APROPRIATE VALUE OF HYPERPARAMETER ,TESTING ACCURACY ON TEST DATA\n",
    "    USING F1-SCORE\n",
    " * PLOTTING THE CONFUSION MATRIX TO GET THE  PRECISOIN ,RECALL VALUE WITH HELP OF HEATMAP\n",
    "  * PRINTING THE TOP 20 FEATURES FOR BOTH POSITIVE AND NEGATIVE WORDS\n",
    "  #\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Fluc2eJIGzB1"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split          #importing the necessary libraries\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import *\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "-De_uLuV5BIh",
    "outputId": "6a256117-34d3-4370-beb5-ad852ee24c25"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ECeKKDS0G4J_"
   },
   "outputs": [],
   "source": [
    "final_processed_data=pd.read_csv(\"C:/Users/Mayank/Desktop/machine learning/appliedaicourse data/lecture 18  knn/final_new_data.csv\")#loading the preprocessed data  with 100k points into dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "lyVHaHeoG6lp",
    "outputId": "4ddf78ca-8792-4778-ab93-5309e6568358"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88521\n",
      "11479\n"
     ]
    }
   ],
   "source": [
    "# getting the counts of 0 and 1 in \"SCORE\" column to know whether it is unbalanced data or not\n",
    "count_of_1=0\n",
    "count_of_0=0\n",
    "for i in final_processed_data['Score']:\n",
    "   if i==1:\n",
    "    count_of_1+=1\n",
    "   else:\n",
    "    count_of_0+=1\n",
    "print(count_of_1)\n",
    "print(count_of_0)\n",
    "#it is an imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zXC7JSnTG9eK"
   },
   "outputs": [],
   "source": [
    "#spliiting the data into train and test data\n",
    "x_train,x_test,y_train,y_test=model_selection.train_test_split(final_processed_data['CleanedText'].values,final_processed_data['Score'].values,test_size=0.2,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "h4N1lWyIHJDa",
    "outputId": "71f0eed3-f948-4b69-8352-5ce6b5c440e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 7677)\n"
     ]
    }
   ],
   "source": [
    "vectorizer=CountVectorizer(min_df=10)#building the vertorizer with word counts equal and more then 2\n",
    "train_bow=vectorizer.fit_transform(x_train)#fitting the model on training data\n",
    "print(train_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "euxhGXSARuT8",
    "outputId": "7bd7a619-e786-45d1-bd6a-ae384916d540"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 7677)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler #standarizing the training  data  \n",
    "x_train_data=StandardScaler( with_mean=False).fit_transform(train_bow)\n",
    "print(x_train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "n6iGM6o-HLgv",
    "outputId": "c9e17afd-3bee-4712-9bb6-888aa5bb37dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_test after bow vectorization  (20000, 7677)\n",
      "shape of x_test after standardization  (20000, 7677)\n"
     ]
    }
   ],
   "source": [
    "test_bow=vectorizer.transform(x_test)#fitting the bow model on test data\n",
    "print(\"shape of x_test after bow vectorization \",test_bow.shape)\n",
    "x_test_data=StandardScaler( with_mean=False).fit_transform(test_bow)#standarizing the test data\n",
    "print(\"shape of x_test after standardization \",x_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1t9cych-W6dK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "chWOpjaYHQJ9"
   },
   "outputs": [],
   "source": [
    "#using time series split method for cross-validation score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=10) \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import uniform\n",
    "data=[10**-4,10**-3,10**-2,10**-1,10**0,10**1,10**2,10**3,10**4]#range of hyperparameter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "rG88j1YPCZA2"
   },
   "outputs": [],
   "source": [
    "lr=LogisticRegression(penalty='l2',class_weight={1:.5,0:.5})#building logistic regression model\n",
    "tuned_parameters=[{'C':data}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "TiPOTRBoVW27",
    "outputId": "9c55c6a7-4a13-4991-dd62-2601c778afde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "LogisticRegression(C=0.001, class_weight={1: 0.5, 0: 0.5}, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "0.952504987808\n"
     ]
    }
   ],
   "source": [
    "#applying the model of logistic regression and using gridsearchcv to find the best hyper parameter\n",
    "%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = GridSearchCV(lr, tuned_parameters, scoring = 'f1', cv=tscv,n_jobs=-1)#building the gridsearchcv model\n",
    "model.fit(x_train_data, y_train)#fiitting the training data\n",
    "\n",
    "print(model.best_estimator_)#printing the best_estimator\n",
    "print(model.score(x_test_data, y_test))#predicting  f1 score on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tfX1tl8tFY1t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.55845076  2.26483878  1.98815951 ...,  7.38021825 -2.68550859\n",
      "  4.84653495]\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(C=0.001,penalty='l2',class_weight={1:.5,0:.5},n_jobs=-1)#again building the model to find best hyperparameter\n",
    "lr.fit(x_train_data,y_train)#fitting the training data\n",
    "z=lr.decision_function(x_train_data)#checking the signed distance of a point from hyperplane\n",
    "print(z)#printing the signed distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O9878ojqngnG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 7677)\n",
      "[[-0.00404381 -0.0055471  -0.00635504 ...,  0.0277215  -0.00865251\n",
      "   0.00910158]]\n"
     ]
    }
   ],
   "source": [
    "wieght_vector=lr.coef_#getting the weight vector\n",
    "print(wieght_vector.shape)#wieght vector shape\n",
    "print(wieght_vector[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PERFORMING SPARSITY CHECK WITH L1 REGULARIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_20k_points=x_train_data[:20000] #first 20k points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#using time series split method for cross-validation score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=10) \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import uniform\n",
    "data=[10**-4,10**-3,10**-2,10**-1,10**0,10**1,10**2,10**3,10**4]#range of hyperparameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr=LogisticRegression(penalty='l1',class_weight={1:.5,0:.5})#building logistic regression model\n",
    "tuned_parameters=[{'C':data}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "LogisticRegression(C=0.1, class_weight={1: 0.5, 0: 0.5}, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#applying the model of logistic regression and using gridsearchcv to find the best hyper parameter\n",
    "%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = GridSearchCV(lr, tuned_parameters, scoring = 'f1', cv=tscv,n_jobs=-1)#building the gridsearchcv model\n",
    "model.fit(first_20k_points, y_train[:20000])#fiitting the training data\n",
    "\n",
    "print(model.best_estimator_)#printing the best_estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight={1: 0.5, 0: 0.5}, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=-1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LogisticRegression(C=0.1,penalty='l1',class_weight={1:.5,0:.5},n_jobs=-1)#again building the model to find best hyperparameter\n",
    "lr.fit(first_20k_points,y_train[:20000])#fitting the training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 7677)\n",
      "[[ 0.          0.00692072  0.         ...,  0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "wieght_vector=lr.coef_#getting the weight vector\n",
    "print(wieght_vector.shape)#wieght vector shape\n",
    "print(wieght_vector[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1625"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(wieght_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THUS HERE ONLY 1625 FEATURES ARE NON_ZERO AND REST OF FEATURES WIEGHTS HAVE BECOME ZERO..SPARSITY CHECK IS POSITIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ***************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eBxTRYWtRsb7"
   },
   "source": [
    "#  PERTUBATION TEST : #\n",
    "    AIM:    TO CHECK FOR MULTI COLLINEARITY  OF FEATURES\n",
    "    STEPS\n",
    "  1.   GETTING THE WIEGHT VECTOR FROM  MODEL AND SAVING IT\n",
    "  2.   ADDING  NOISE TO THE  TRAINING DATA TO GET NEW  TRAINING  DATA\n",
    "  3. FITTING THE MODEL AGAIN ON NEW DATA\n",
    "  4. GETTING THE WIEGHT VECTOR FROM THIS MODEL\n",
    "  5.ADDING SMALL VALUE TO WEIGHT VECTOR OF BOTH TRAINNG  DATA TO REMOVE ANY ERROR\n",
    "  6. FINDING THE PERCENTAGE CHANGE VECTOR \n",
    "  7. GEETING HOW MANY GEATURE HAS CHANGED USING SOME THRESHOLD VALUE( HERE TAKING IT AS  100)\n",
    "  8. PLOTTING THE  QUANTILES WITH THIER PERCENTAGE WIGHT  VALUE TO CHECK IF COLLINEARITY EXITS OR NOT\n",
    "  \n",
    "  #  RESULT : TO KNOW WHETHER FEATURES ARE MULTICOLLINEAR OR NOT  #\n",
    "#   AND TO KNOW WHETHER MODEL IS RELIABLE OR NOT #\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "KjO5al3OpBHN"
   },
   "outputs": [],
   "source": [
    "#here,we are adding noise to the data \n",
    "from scipy.stats import norm\n",
    "noise=norm.rvs(size=1)#noise\n",
    "x_train_data.data+=noise#adding noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qv9Pk61dIYzP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of our new train data  after adding noise is :  (80000, 7677)\n"
     ]
    }
   ],
   "source": [
    "print('shape of our new train data  after adding noise is : ',x_train_data.shape)#printing shape of new training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Q0VNtjb8R-7F"
   },
   "outputs": [],
   "source": [
    "#uilding the model using timeSeriesSplit\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=10) # 10 spilts cross validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import uniform\n",
    "data=[10**-4,10**-3,10**-2,10**-1,10**0,10**1,10**2,10**3,10**4]#value range of hyper parameter for grid searchcv\n",
    "lr=LogisticRegression(penalty='l2',class_weight={1:.5,0:.5},n_jobs=-1)#building the model\n",
    "tuned_parameters=[{'C':data}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TyMjKFZOSdnz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "best estimator of our new data is:  LogisticRegression(C=0.001, class_weight={1: 0.5, 0: 0.5}, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=-1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = GridSearchCV(lr, tuned_parameters, scoring = 'f1', cv=tscv,n_jobs=-1)#building the gridsearchcv model\n",
    "model.fit(x_train_data, y_train)#fiitting the training data\n",
    "\n",
    "print('best estimator of our new data is: ',model.best_estimator_)#printing the best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p6CYIA4sUAbZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 7677)\n"
     ]
    }
   ],
   "source": [
    "# again building the model for finding the wieght vector of the words from model\n",
    "lr=LogisticRegression(C=0.001,penalty='l2',class_weight={1:.5,0:.5},n_jobs=-1)#building the logistic regression model\n",
    "lr.fit(x_train_data,y_train)#fiting the training model\n",
    "new_wieght_vector=lr.coef_\n",
    "print(new_wieght_vector.shape)#printing shape of wieght vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "kvT7CUuIVEIp"
   },
   "outputs": [],
   "source": [
    "percent_change_vec=np.ones((1,17204))#generating the percent_change_vetor to store the percentage change  values for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "h2gPDOfsBGPZ"
   },
   "outputs": [],
   "source": [
    "wieght_vector=wieght_vector+10**-6 #adding some values to wieght vector to avoid error while division\n",
    "      \n",
    "new_wieght_vector=new_wieght_vector+10**-6 #adding some values to wieght vector to avoid error while division\n",
    "      \n",
    "percent_change_vec=abs((wieght_vector-new_wieght_vector)/wieght_vector)*100#calculating the percentage change in the vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XUi-owIl7_k-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6124.13518164\n"
     ]
    }
   ],
   "source": [
    "x=(wieght_vector[0][2]-new_wieght_vector[0][2])/wieght_vector[0][2]#just checking randomly that every value is positve in percent_change_vector \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P4k621dtBJGk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of percent change wieght vector is (1, 7677)\n"
     ]
    }
   ],
   "source": [
    "print('shape of percent change wieght vector is', percent_change_vec.shape)#printing shape of percent_change_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "hi1oC_R8BNSJ"
   },
   "outputs": [],
   "source": [
    "per_change_df=pd.DataFrame(percent_change_vec.T,columns=['CHANGE'])#building a dataframe from wight vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yJ0gARInBXwH"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHANGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.114007e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.793059e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.124135e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.546318e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.072202e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CHANGE\n",
       "0  4.114007e+05\n",
       "1  1.793059e+02\n",
       "2  6.124135e+05\n",
       "3  6.546318e+05\n",
       "4  1.072202e+06"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_change_df.head()#getting first 5 values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JthxyW_W2XAh"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHANGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.677000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.163010e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.943429e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.020788e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.567501e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.955684e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.224095e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.119868e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CHANGE\n",
       "count  7.677000e+03\n",
       "mean   8.163010e+05\n",
       "std    8.943429e+05\n",
       "min    3.020788e-01\n",
       "25%    6.567501e+04\n",
       "50%    5.955684e+05\n",
       "75%    1.224095e+06\n",
       "max    1.119868e+07"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_Df=per_change_df.sort_values('CHANGE',ascending=True,axis=0)#sorting the dataframe to calculate the quantiles values\n",
    "sorted_Df.describe()#describe function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "irRAKZ7-KT9v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted_Data 0.00th quantiles is   0.302\n",
      "sorted_Data 0.05th quantiles is  36.889\n",
      "sorted_Data 0.10th quantiles is  62.904\n",
      "sorted_Data 0.15th quantiles is 102.959\n",
      "sorted_Data 0.20th quantiles is 528.746\n",
      "sorted_Data 0.25th quantiles is 65675.014\n",
      "sorted_Data 0.30th quantiles is 180460.231\n",
      "sorted_Data 0.35th quantiles is 279055.538\n",
      "sorted_Data 0.40th quantiles is 378386.003\n",
      "sorted_Data 0.45th quantiles is 482543.855\n",
      "sorted_Data 0.50th quantiles is 595568.425\n",
      "sorted_Data 0.55th quantiles is 703414.610\n",
      "sorted_Data 0.60th quantiles is 811447.629\n",
      "sorted_Data 0.65th quantiles is 937978.515\n",
      "sorted_Data 0.70th quantiles is 1076080.247\n",
      "sorted_Data 0.75th quantiles is 1224094.822\n",
      "sorted_Data 0.80th quantiles is 1410348.577\n",
      "sorted_Data 0.85th quantiles is 1629372.501\n",
      "sorted_Data 0.90th quantiles is 1950475.872\n",
      "sorted_Data 0.95th quantiles is 2545719.779\n",
      "sorted_Data 1.00th quantiles is 11198680.280\n"
     ]
    }
   ],
   "source": [
    "quantiles=list( i/100 for i in range(0,101,5))#building the list of quantiles value \n",
    "for i in quantiles:\n",
    "  print('sorted_Data {:.2f}th quantiles is {:7.3f}'.format(i,sorted_Df['CHANGE'].quantile(i)))#printing the quantiles and thier coreesponding values\n",
    "\n",
    "      \n",
    "      \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gVBhyVa7MhfT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted_Data 0.95th quantiles is 2545719.779\n",
      "sorted_Data 0.96th quantiles is 2740753.344\n",
      "sorted_Data 0.97th quantiles is 2907890.640\n",
      "sorted_Data 0.98th quantiles is 3243208.220\n",
      "sorted_Data 0.99th quantiles is 3921466.304\n",
      "sorted_Data 1.00th quantiles is 11198680.280\n"
     ]
    }
   ],
   "source": [
    "quantiles=list( i/100 for i in range(95,101,1))#printing the last percentiles values because this region is showing abrupt change\n",
    "percent_change_list=[]#empty percent_change\n",
    "for i in quantiles:\n",
    "  print('sorted_Data {:.2f}th quantiles is {:7.3f}'.format(i,sorted_Df['CHANGE'].quantile(i)))\n",
    "  percent_change_list.append(sorted_Df['CHANGE'].quantile(i))#building the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wkB8LGD3F2ro"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2545719.778685397, 2740753.3441018667, 2907890.6404516995, 3243208.219537627, 3921466.30395979, 11198680.279986566]\n",
      "[2545719.78, 2740753.34, 2907890.64, 3243208.22, 3921466.3, 11198680.28]\n",
      "[0.95, 0.96, 0.97, 0.98, 0.99, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(percent_change_list)\n",
    "my_formatted_list = [ '%.2f' % elem for elem in percent_change_list ]#formatted list with string values in it\n",
    "my_formatted_list=[float(i) for i in my_formatted_list]#formatted list with flaot values in it\n",
    "print(my_formatted_list)#printing formatted list\n",
    "print(quantiles)#printing quantiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pHGWehRbLX7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15e71d05358>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAERCAYAAACU1LsdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15e71d05390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.show() \n",
    "plt.xlabel('QUANTILES VALUES')\n",
    "plt.ylabel('PERCENTAGE VALUES FOR QUANTILES')\n",
    "plt.plot(quantiles,my_formatted_list,'r--' ,label='PERCENTAGE VALUES FOR QUANTILES')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hkT2E5g5S0Jy"
   },
   "source": [
    "### FROM THE ABOVE VISUALIZATION , MAIN POINTS ARE:.###\n",
    "\n",
    "1.   THAT ONLY 1% OF FEATURES GOT AFFECTED AFTER ADDING NOISE TO THE DATA. \n",
    "2.    VERY LESS COLLINEARITY OF DATA IS PRESENT  ,BECAUSE MOST OF THE WEIGHT VECTORS VALUES  REMAINS SAME \n",
    "3.THERFORE, OUR MODEL IS RELIABLE AND WE CAN PROCEED FURTHER TO CHECK ACCURACY ON TEST DATA \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_7wUeBTCZk5X"
   },
   "source": [
    "## CALCULATING  THE BEST HYPERPARAMETER ON TRAIN  DATA AND CALCULATING THE ACCURACY USING F1-SCORE AND PLOTTING IT  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "BZF-q9eutTFs"
   },
   "outputs": [],
   "source": [
    "#using time series split method for cross-validation score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=10) \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import uniform\n",
    "data=[10**-4,10**-3,10**-2,10**-1,10**0,10**1,10**2,10**3,10**4]#range of hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4Q_AGHBgqkJA"
   },
   "outputs": [],
   "source": [
    "lr=LogisticRegression(penalty='l2',class_weight={1:.5,0:.5},n_jobs=-1)#building logistic regression model\n",
    "tuned_parameters=[{'C':data}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_9W2TEOxquDR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=10),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight={1: 0.5, 0: 0.5}, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=-1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid=[{'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying the model of logistic regression and using gridsearchcv to find the best hyper parameter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = GridSearchCV(lr, tuned_parameters, scoring = 'f1', cv=tscv,n_jobs=-1)#building the gridsearchcv model\n",
    "model.fit(x_train_data, y_train)#fiitting the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T7y5hJNi0B2C"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.371375</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.947138</td>\n",
       "      <td>0.957927</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 0.0001}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.943679</td>\n",
       "      <td>0.951138</td>\n",
       "      <td>0.951348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947087</td>\n",
       "      <td>0.960685</td>\n",
       "      <td>0.947204</td>\n",
       "      <td>0.961764</td>\n",
       "      <td>0.947306</td>\n",
       "      <td>0.962298</td>\n",
       "      <td>0.915326</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.003052</td>\n",
       "      <td>0.003410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.322609</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.956032</td>\n",
       "      <td>0.979998</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.949230</td>\n",
       "      <td>0.982080</td>\n",
       "      <td>0.958458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956785</td>\n",
       "      <td>0.979595</td>\n",
       "      <td>0.953855</td>\n",
       "      <td>0.979777</td>\n",
       "      <td>0.958485</td>\n",
       "      <td>0.979060</td>\n",
       "      <td>1.347613</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>0.000774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.062930</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.954233</td>\n",
       "      <td>0.991260</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.954569</td>\n",
       "      <td>0.996582</td>\n",
       "      <td>0.957323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952264</td>\n",
       "      <td>0.988897</td>\n",
       "      <td>0.949273</td>\n",
       "      <td>0.988257</td>\n",
       "      <td>0.952498</td>\n",
       "      <td>0.987060</td>\n",
       "      <td>2.303116</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.002811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.760476</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.946258</td>\n",
       "      <td>0.995863</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.955969</td>\n",
       "      <td>0.999611</td>\n",
       "      <td>0.949000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942686</td>\n",
       "      <td>0.993463</td>\n",
       "      <td>0.942195</td>\n",
       "      <td>0.992322</td>\n",
       "      <td>0.943229</td>\n",
       "      <td>0.990765</td>\n",
       "      <td>5.338173</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.004786</td>\n",
       "      <td>0.002862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.133621</td>\n",
       "      <td>0.007087</td>\n",
       "      <td>0.937421</td>\n",
       "      <td>0.997608</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.951520</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933176</td>\n",
       "      <td>0.995794</td>\n",
       "      <td>0.932231</td>\n",
       "      <td>0.994546</td>\n",
       "      <td>0.941011</td>\n",
       "      <td>0.991688</td>\n",
       "      <td>9.638477</td>\n",
       "      <td>0.006497</td>\n",
       "      <td>0.006530</td>\n",
       "      <td>0.002659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19.005972</td>\n",
       "      <td>0.009486</td>\n",
       "      <td>0.932540</td>\n",
       "      <td>0.997968</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.946958</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.936861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929044</td>\n",
       "      <td>0.996475</td>\n",
       "      <td>0.925472</td>\n",
       "      <td>0.995262</td>\n",
       "      <td>0.940762</td>\n",
       "      <td>0.991773</td>\n",
       "      <td>14.429250</td>\n",
       "      <td>0.005588</td>\n",
       "      <td>0.007443</td>\n",
       "      <td>0.002636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.856343</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.927830</td>\n",
       "      <td>0.998044</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 100}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.936848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.922755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930328</td>\n",
       "      <td>0.996389</td>\n",
       "      <td>0.924585</td>\n",
       "      <td>0.995407</td>\n",
       "      <td>0.940679</td>\n",
       "      <td>0.991742</td>\n",
       "      <td>13.631132</td>\n",
       "      <td>0.004942</td>\n",
       "      <td>0.006365</td>\n",
       "      <td>0.002637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26.530732</td>\n",
       "      <td>0.009849</td>\n",
       "      <td>0.925073</td>\n",
       "      <td>0.998082</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'C': 1000}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.929874</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.907760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930013</td>\n",
       "      <td>0.996389</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.995680</td>\n",
       "      <td>0.940154</td>\n",
       "      <td>0.992032</td>\n",
       "      <td>29.809774</td>\n",
       "      <td>0.005851</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>0.002551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30.367647</td>\n",
       "      <td>0.004799</td>\n",
       "      <td>0.923287</td>\n",
       "      <td>0.998256</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'C': 10000}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.927953</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919329</td>\n",
       "      <td>0.997717</td>\n",
       "      <td>0.921226</td>\n",
       "      <td>0.995689</td>\n",
       "      <td>0.940679</td>\n",
       "      <td>0.991688</td>\n",
       "      <td>29.880901</td>\n",
       "      <td>0.004307</td>\n",
       "      <td>0.008920</td>\n",
       "      <td>0.002598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
       "0       1.371375         0.009375         0.947138          0.957927  0.0001   \n",
       "1       2.322609         0.007812         0.956032          0.979998   0.001   \n",
       "2       4.062930         0.001562         0.954233          0.991260    0.01   \n",
       "3       7.760476         0.007813         0.946258          0.995863     0.1   \n",
       "4      14.133621         0.007087         0.937421          0.997608       1   \n",
       "5      19.005972         0.009486         0.932540          0.997968      10   \n",
       "6      19.856343         0.007924         0.927830          0.998044     100   \n",
       "7      26.530732         0.009849         0.925073          0.998082    1000   \n",
       "8      30.367647         0.004799         0.923287          0.998256   10000   \n",
       "\n",
       "          params  rank_test_score  split0_test_score  split0_train_score  \\\n",
       "0  {'C': 0.0001}                3           0.943679            0.951138   \n",
       "1   {'C': 0.001}                1           0.949230            0.982080   \n",
       "2    {'C': 0.01}                2           0.954569            0.996582   \n",
       "3     {'C': 0.1}                4           0.955969            0.999611   \n",
       "4       {'C': 1}                5           0.951520            1.000000   \n",
       "5      {'C': 10}                6           0.946958            1.000000   \n",
       "6     {'C': 100}                7           0.936848            1.000000   \n",
       "7    {'C': 1000}                8           0.929874            1.000000   \n",
       "8   {'C': 10000}                9           0.927953            1.000000   \n",
       "\n",
       "   split1_test_score       ...         split7_test_score  split7_train_score  \\\n",
       "0           0.951348       ...                  0.947087            0.960685   \n",
       "1           0.958458       ...                  0.956785            0.979595   \n",
       "2           0.957323       ...                  0.952264            0.988897   \n",
       "3           0.949000       ...                  0.942686            0.993463   \n",
       "4           0.941962       ...                  0.933176            0.995794   \n",
       "5           0.936861       ...                  0.929044            0.996475   \n",
       "6           0.922755       ...                  0.930328            0.996389   \n",
       "7           0.907760       ...                  0.930013            0.996389   \n",
       "8           0.903832       ...                  0.919329            0.997717   \n",
       "\n",
       "   split8_test_score  split8_train_score  split9_test_score  \\\n",
       "0           0.947204            0.961764           0.947306   \n",
       "1           0.953855            0.979777           0.958485   \n",
       "2           0.949273            0.988257           0.952498   \n",
       "3           0.942195            0.992322           0.943229   \n",
       "4           0.932231            0.994546           0.941011   \n",
       "5           0.925472            0.995262           0.940762   \n",
       "6           0.924585            0.995407           0.940679   \n",
       "7           0.922078            0.995680           0.940154   \n",
       "8           0.921226            0.995689           0.940679   \n",
       "\n",
       "   split9_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.962298      0.915326        0.007654        0.003052   \n",
       "1            0.979060      1.347613        0.007812        0.003460   \n",
       "2            0.987060      2.303116        0.004687        0.003186   \n",
       "3            0.990765      5.338173        0.007813        0.004786   \n",
       "4            0.991688      9.638477        0.006497        0.006530   \n",
       "5            0.991773     14.429250        0.005588        0.007443   \n",
       "6            0.991742     13.631132        0.004942        0.006365   \n",
       "7            0.992032     29.809774        0.005851        0.008258   \n",
       "8            0.991688     29.880901        0.004307        0.008920   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.003410  \n",
       "1         0.000774  \n",
       "2         0.002811  \n",
       "3         0.002862  \n",
       "4         0.002659  \n",
       "5         0.002636  \n",
       "6         0.002637  \n",
       "7         0.002551  \n",
       "8         0.002598  \n",
       "\n",
       "[9 rows x 31 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(model.cv_results_)# getting varoius cv_scores and train_scores various values of alpha given as parameter and storing it in a dataframe\n",
    "results#printing the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "19Sfrfuv0yKn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.2862463174302876, 4.3968129672200318, 4.5767022275204798, 5.3741652913736448, 6.2578765329667103, 6.7460040101474439, 7.2170415778466062, 7.4926855714309131, 7.6713443582323571]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15e72866b70>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njGki/j/yBg3umLMdWgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15e71fb5f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "mean_test_score=list(results['mean_test_score'])#taking mean_test_score values of various alpha into a list\n",
    "mean_train_score=list(results['mean_train_score'])#taking mean_train_score values of varoius alpha into a list\n",
    "cv_error_list=[]\n",
    "train_error_list=[]\n",
    "for i  in mean_test_score:\n",
    "   i=1-i\n",
    "   i=i*100\n",
    "   cv_error_list.append(i)#appending the list with cv_error \n",
    "for i  in mean_train_score:\n",
    "   i=1-i\n",
    "   i=i*100\n",
    "   train_error_list.append(i)#appending  the list with train_error     \n",
    "    \n",
    "print(cv_error_list)\n",
    "C_values_in_10_power=[-4,-3,-2,-1,0,1,2,3,4]#list of alpha values in power of 10\n",
    "plt.plot(C_values_in_10_power,cv_error_list,label='cv_error')#plotting alpha with cv_error\n",
    "plt.plot(C_values_in_10_power,train_error_list,label='train_error')#plotting aplhawith train_error\n",
    "plt.xlabel('C value in  power of 10 ')\n",
    "plt.ylabel('cv error and train error')\n",
    "plt.legend(loc='best')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7BOpkgvi7gmK"
   },
   "source": [
    "# <font color=DarkSlateGray>From here,the best hyperparameter value is c=0.001 or alpha=1000 <font>#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rqlZDby4HdbA"
   },
   "source": [
    "# NOW GETTING THE TOP 30 FEATURES WORDS FOR POSITIVE AND NEGATIVE WORDS#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kfDwrnnM13r_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight={1: 0.5, 0: 0.5}, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=-1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#building the model using timeSeriesSplit\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=10) # 10 spilts cross validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression(C=0.001,penalty='l2',class_weight={1:.5,0:.5},n_jobs=-1)#building logistic regression model\n",
    "lr.fit(x_train_data,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zDmgDoyt5ccO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00411401 -0.00549033 -0.00612414 ...,  0.02776355 -0.00862934\n",
      "  0.00916463]\n"
     ]
    }
   ],
   "source": [
    "z=lr.coef_[0]#getting the wieght of the vector \n",
    "print(z)#printing the wieght of the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vr6abL8nuPSa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of wieght vector is: (7677,)\n"
     ]
    }
   ],
   "source": [
    "a=z.argsort()\n",
    "print('shape of wieght vector is:',a.shape)\n",
    "top_30_positive=np.take(vectorizer.get_feature_names(),a[17174:])\n",
    "top_30_negative=np.take(vectorizer.get_feature_names(),a[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qWtmad7zv7ah"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITVE WORDS\t|\tNEGATIVE WORDS\n"
     ]
    }
   ],
   "source": [
    "print(\"POSITVE WORDS\\t|\\tNEGATIVE WORDS\")\n",
    "for i,j in zip(top_30_positive,top_30_negative):\n",
    "    print( '{}\\t\\t|\\t\\t{}'.format(i,j) )#printing the postive and negative words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iIPcvIHIN3Qq"
   },
   "source": [
    "# <font color=MidnightBlue><u><i>USING BEST HYPERPARAMETER VALUE ON TEST DATA AND PLOTTING THE CONFUSION MATRIX WITH HEATMAP <u><i><font>#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2DLMaFSbvWcP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 96.320%\n",
      "Precision on test set: 0.961\n",
      "Recall on test set: 0.998\n",
      "F1-Score on test set: 0.979\n",
      "Confusion Matrix of test set:\n",
      " [ [TN  FP]\n",
      " [FN TP] ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x15e77d4bef0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15e7ca10b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Testing Accuracy on Test data  \n",
    "import seaborn as sns #importing seaborn as sns\n",
    "from sklearn.metrics import *#importing varoius metrics from sklearn\n",
    "#building the model\n",
    "lr.fit(x_test_data,y_test)\n",
    "y_pred = lr.predict(x_test_data) \n",
    "print(\"Accuracy on test set: %0.3f%%\"%(accuracy_score(y_test, y_pred)*100))#printing accuracy\n",
    "print(\"Precision on test set: %0.3f\"%(precision_score(y_test, y_pred)))#printing precision score\n",
    "print(\"Recall on test set: %0.3f\"%(recall_score(y_test, y_pred))) #printing recall\n",
    "print(\"F1-Score on test set: %0.3f\"%(f1_score(y_test, y_pred))) \n",
    "print(\"Confusion Matrix of test set:\\n [ [TN  FP]\\n [FN TP] ]\\n\") \n",
    "df_cm = pd.DataFrame(confusion_matrix(y_test, y_pred), range(2),range(2)) #generating the heatmap for confusion matrix\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yN8gMC0FQ0Wg"
   },
   "source": [
    "# <font color=MediumOrchid><u><i>FROM THE ABOVE OBSERVATIONS ,IT IS FOUND THAT THE BEST HYPERPARAMETER IS FOUND AS APLHA=1000  AND IT IS ALSO HAVING HIGH PRECISION,RECALL VALUE ON TEST DATA<u><i> <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "HfmdUQ-UNrpN"
   },
   "outputs": [],
   "source": [
    "#BOW VECTORIZATION IS COMPLETED FOR LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "VwaVpm9JR-mv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lr.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
